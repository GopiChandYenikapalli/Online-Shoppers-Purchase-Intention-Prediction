{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c92fef44",
   "metadata": {
    "id": "c92fef44"
   },
   "source": [
    "# 1.0 Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f266f722",
   "metadata": {
    "id": "f266f722"
   },
   "outputs": [],
   "source": [
    "# Import all required libraries\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import seaborn as sns\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf6817b",
   "metadata": {
    "id": "9cf6817b"
   },
   "source": [
    "# 2.0 Load the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7af73c9",
   "metadata": {},
   "source": [
    "Loading the cleaned and preprossed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1501bf14",
   "metadata": {
    "id": "1501bf14"
   },
   "outputs": [],
   "source": [
    "#load the cleaned data \n",
    "X_train = pd.read_csv(\"shopping_X_train.csv\")\n",
    "X_test = pd.read_csv(\"shopping_X_test.csv\")\n",
    "y_train = pd.read_csv(\"shopping_y_train.csv\")\n",
    "y_test = pd.read_csv(\"shopping_y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f078baf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "5f078baf",
    "outputId": "fbb31021-2815-42b8-a2b3-67b63a58586a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.695244</td>\n",
       "      <td>-0.464002</td>\n",
       "      <td>-0.401578</td>\n",
       "      <td>-0.249008</td>\n",
       "      <td>0.002346</td>\n",
       "      <td>-0.234227</td>\n",
       "      <td>-0.459606</td>\n",
       "      <td>-0.757614</td>\n",
       "      <td>-0.320331</td>\n",
       "      <td>-0.309603</td>\n",
       "      <td>2.522763</td>\n",
       "      <td>-0.084367</td>\n",
       "      <td>-2.449490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.094939</td>\n",
       "      <td>-0.200020</td>\n",
       "      <td>-0.401578</td>\n",
       "      <td>-0.249008</td>\n",
       "      <td>0.160364</td>\n",
       "      <td>0.430788</td>\n",
       "      <td>-0.459606</td>\n",
       "      <td>-0.628451</td>\n",
       "      <td>2.589939</td>\n",
       "      <td>-0.309603</td>\n",
       "      <td>-0.396391</td>\n",
       "      <td>-0.084367</td>\n",
       "      <td>0.408248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.695244</td>\n",
       "      <td>-0.464002</td>\n",
       "      <td>-0.401578</td>\n",
       "      <td>-0.249008</td>\n",
       "      <td>-0.562004</td>\n",
       "      <td>-0.549309</td>\n",
       "      <td>-0.459606</td>\n",
       "      <td>-0.657154</td>\n",
       "      <td>-0.320331</td>\n",
       "      <td>-0.309603</td>\n",
       "      <td>-0.396391</td>\n",
       "      <td>11.852924</td>\n",
       "      <td>-2.449490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.205214</td>\n",
       "      <td>0.008264</td>\n",
       "      <td>-0.401578</td>\n",
       "      <td>-0.249008</td>\n",
       "      <td>1.401933</td>\n",
       "      <td>0.681911</td>\n",
       "      <td>-0.459606</td>\n",
       "      <td>-0.843723</td>\n",
       "      <td>-0.320331</td>\n",
       "      <td>-0.309603</td>\n",
       "      <td>2.522763</td>\n",
       "      <td>-0.084367</td>\n",
       "      <td>-2.449490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.805519</td>\n",
       "      <td>0.522158</td>\n",
       "      <td>1.975666</td>\n",
       "      <td>0.500311</td>\n",
       "      <td>1.311638</td>\n",
       "      <td>1.896665</td>\n",
       "      <td>-0.373168</td>\n",
       "      <td>-0.732210</td>\n",
       "      <td>1.930372</td>\n",
       "      <td>-0.309603</td>\n",
       "      <td>-0.396391</td>\n",
       "      <td>-0.084367</td>\n",
       "      <td>0.408248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6   \n",
       "0 -0.695244 -0.464002 -0.401578 -0.249008  0.002346 -0.234227 -0.459606  \\\n",
       "1 -0.094939 -0.200020 -0.401578 -0.249008  0.160364  0.430788 -0.459606   \n",
       "2 -0.695244 -0.464002 -0.401578 -0.249008 -0.562004 -0.549309 -0.459606   \n",
       "3  0.205214  0.008264 -0.401578 -0.249008  1.401933  0.681911 -0.459606   \n",
       "4  0.805519  0.522158  1.975666  0.500311  1.311638  1.896665 -0.373168   \n",
       "\n",
       "          7         8         9        10         11        12  \n",
       "0 -0.757614 -0.320331 -0.309603  2.522763  -0.084367 -2.449490  \n",
       "1 -0.628451  2.589939 -0.309603 -0.396391  -0.084367  0.408248  \n",
       "2 -0.657154 -0.320331 -0.309603 -0.396391  11.852924 -2.449490  \n",
       "3 -0.843723 -0.320331 -0.309603  2.522763  -0.084367 -2.449490  \n",
       "4 -0.732210  1.930372 -0.309603 -0.396391  -0.084367  0.408248  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b7efb35",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "6b7efb35",
    "outputId": "baf19106-16fa-4d6f-de3f-c20cbcb961c0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.695244</td>\n",
       "      <td>-0.464002</td>\n",
       "      <td>-0.401578</td>\n",
       "      <td>-0.249008</td>\n",
       "      <td>-0.697448</td>\n",
       "      <td>-0.629112</td>\n",
       "      <td>1.614895</td>\n",
       "      <td>3.246437</td>\n",
       "      <td>-0.320331</td>\n",
       "      <td>-0.309603</td>\n",
       "      <td>2.522763</td>\n",
       "      <td>-0.084367</td>\n",
       "      <td>-2.449490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.805519</td>\n",
       "      <td>7.748440</td>\n",
       "      <td>-0.401578</td>\n",
       "      <td>-0.249008</td>\n",
       "      <td>0.047494</td>\n",
       "      <td>-0.319019</td>\n",
       "      <td>-0.459606</td>\n",
       "      <td>-0.261692</td>\n",
       "      <td>0.115159</td>\n",
       "      <td>-0.309603</td>\n",
       "      <td>-0.396391</td>\n",
       "      <td>-0.084367</td>\n",
       "      <td>0.408248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.695244</td>\n",
       "      <td>-0.464002</td>\n",
       "      <td>-0.401578</td>\n",
       "      <td>-0.249008</td>\n",
       "      <td>-0.674874</td>\n",
       "      <td>-0.590638</td>\n",
       "      <td>-0.459606</td>\n",
       "      <td>0.146526</td>\n",
       "      <td>-0.320331</td>\n",
       "      <td>-0.309603</td>\n",
       "      <td>-0.396391</td>\n",
       "      <td>-0.084367</td>\n",
       "      <td>0.408248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.094939</td>\n",
       "      <td>0.104574</td>\n",
       "      <td>-0.401578</td>\n",
       "      <td>-0.249008</td>\n",
       "      <td>-0.268542</td>\n",
       "      <td>-0.417506</td>\n",
       "      <td>-0.459606</td>\n",
       "      <td>-0.817890</td>\n",
       "      <td>-0.320331</td>\n",
       "      <td>-0.309603</td>\n",
       "      <td>-0.396391</td>\n",
       "      <td>-0.084367</td>\n",
       "      <td>0.408248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.505366</td>\n",
       "      <td>-0.136201</td>\n",
       "      <td>-0.401578</td>\n",
       "      <td>-0.249008</td>\n",
       "      <td>-0.539430</td>\n",
       "      <td>-0.522562</td>\n",
       "      <td>-0.459606</td>\n",
       "      <td>-0.680116</td>\n",
       "      <td>-0.320331</td>\n",
       "      <td>-0.309603</td>\n",
       "      <td>2.522763</td>\n",
       "      <td>-0.084367</td>\n",
       "      <td>-2.449490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6   \n",
       "0 -0.695244 -0.464002 -0.401578 -0.249008 -0.697448 -0.629112  1.614895  \\\n",
       "1  0.805519  7.748440 -0.401578 -0.249008  0.047494 -0.319019 -0.459606   \n",
       "2 -0.695244 -0.464002 -0.401578 -0.249008 -0.674874 -0.590638 -0.459606   \n",
       "3 -0.094939  0.104574 -0.401578 -0.249008 -0.268542 -0.417506 -0.459606   \n",
       "4  0.505366 -0.136201 -0.401578 -0.249008 -0.539430 -0.522562 -0.459606   \n",
       "\n",
       "          7         8         9        10        11        12  \n",
       "0  3.246437 -0.320331 -0.309603  2.522763 -0.084367 -2.449490  \n",
       "1 -0.261692  0.115159 -0.309603 -0.396391 -0.084367  0.408248  \n",
       "2  0.146526 -0.320331 -0.309603 -0.396391 -0.084367  0.408248  \n",
       "3 -0.817890 -0.320331 -0.309603 -0.396391 -0.084367  0.408248  \n",
       "4 -0.680116 -0.320331 -0.309603  2.522763 -0.084367 -2.449490  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "030cefd8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "030cefd8",
    "outputId": "3b71b566-d0ec-4bfc-a196-b7b2ebef7d07"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REVENUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   REVENUE\n",
       "0        0\n",
       "1        1\n",
       "2        0\n",
       "3        0\n",
       "4        1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "012caa57",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "012caa57",
    "outputId": "2a12188c-131d-4ba5-9b29-5911e6356475"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REVENUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   REVENUE\n",
       "0        0\n",
       "1        1\n",
       "2        0\n",
       "3        0\n",
       "4        0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c633e410",
   "metadata": {
    "id": "c633e410"
   },
   "source": [
    "# 3.0 Performance metrics Identification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73539363",
   "metadata": {
    "id": "73539363"
   },
   "source": [
    "### As this company is new to the market and wants to spend more on marketing campaigns to reach as many potential customers, building its own brand and focusing on product sales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9882df77",
   "metadata": {
    "id": "9882df77"
   },
   "source": [
    "True Positives (TP): Users who were correctly identified by the model as potential customers who made a purchase.\n",
    "\n",
    "False Positives (FP): Users who were incorrectly identified by the model as potential customers who made a purchase, but in reality, they did not.\n",
    "\n",
    "True Negatives (TN): Users who were correctly identified by the model as non-potential customers who did not make a purchase.\n",
    "\n",
    "False Negatives (FN): Users who were incorrectly identified by the model as non-potential customers who did not make a purchase, but in reality, they did."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2a1045",
   "metadata": {
    "id": "7a2a1045"
   },
   "source": [
    "##### Selecting Performace metrics\n",
    "\n",
    "Clearly, our data set is imblanced and the majority class is 0 (not purchased) and the minority class is 1 (purchased). If we choose accuracy, it will focus on the majority class, which is not good in our case. Then we need to focus on Recall, Precision and F1 score.\n",
    "\n",
    "Recall and precision score depends on the specific goal of the analysis and the trade-off between identifying all positive instances (high recall) and minimizing the number of false positives (high precision).\n",
    "\n",
    "To minimize the number of false positives, even if it means potentially missing some positive instances, then precision should be the primary metric to focus on. A high precision means that the model is able to correctly identify positive instances with a high degree of certainty, which is important for minimizing the cost of false positives, such as wasting resources on marketing campaigns to non-interested customers. however the company is more concerned with not missing out on potential customers and wants to minimize False Negatives (FN), they prioritize maximizing Recall, which measures the proportion of true positives among all actual positive cases (TP / (TP + FN)). A higher Recall score indicates that the model is better at identifying all positive cases, even if it means making more false positive predictions that meansidentify all users who are likely to make a purchase, regardless of the number of false positives.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78432e70",
   "metadata": {
    "id": "78432e70"
   },
   "source": [
    "#### Recall Score- Performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a812878",
   "metadata": {
    "id": "6a812878"
   },
   "source": [
    "# 3.0 Model the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d58497",
   "metadata": {
    "id": "32d58497"
   },
   "source": [
    "## 3.1 Fit and test a Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d98be697",
   "metadata": {
    "id": "d98be697"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 62.5 ms\n",
      "Wall time: 153 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "log_reg_model = LogisticRegression(penalty=None, max_iter=900)\n",
    "_ = log_reg_model.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "401ce3db",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "401ce3db",
    "outputId": "cd6bb206-0a40-4a35-d30e-35187786a5a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************\n",
      "Recall Score:     0.7454545454545455\n",
      "************************************\n",
      "Accuracy Score:   0.874831035414977\n",
      "Precision Score:  0.5593451568894953\n",
      "F1 Score:         0.6391270459859704\n",
      "************************************\n",
      "Confusion Matrix: [[2826  323]\n",
      " [ 140  410]]\n",
      "CPU times: total: 46.9 ms\n",
      "Wall time: 93.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# evaluate the model\n",
    "# predict on test data with default threshold\n",
    "y_pred = log_reg_model.predict(X_test)\n",
    "\n",
    "# adjust the threshold and predict again\n",
    "new_threshold = 0.3\n",
    "y_pred_thresh = (y_pred >= new_threshold).astype(int)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "# calculate evaluation metrics with adjusted threshold\n",
    "print(\"************************************\")\n",
    "print(f\"{'Recall Score:':18}{recall_score(y_test, y_pred_thresh)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Accuracy Score: ':18}{accuracy_score(y_test, y_pred_thresh)}\")\n",
    "print(f\"{'Precision Score: ':18}{precision_score(y_test, y_pred_thresh)}\")\n",
    "print(f\"{'F1 Score: ':18}{f1_score(y_test, y_pred_thresh)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Confusion Matrix: ':18}{confusion_matrix(y_test, y_pred_thresh)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bdadce6",
   "metadata": {
    "id": "2bdadce6"
   },
   "outputs": [],
   "source": [
    "lr_default_recall = recall_score(y_test, y_pred_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e104b1",
   "metadata": {
    "id": "f7e104b1"
   },
   "source": [
    "# 3.2 Fit a LogisticRegression model with Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f21f08a2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f21f08a2",
    "outputId": "845ec1ac-c979-4e98-826a-320c242c15d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n",
      "The best recall score is 0.7448074807480749\n",
      "... with parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 5}\n",
      "CPU times: total: 1.12 s\n",
      "Wall time: 8.12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score_measure = \"recall\"\n",
    "kfolds = 3\n",
    "param_grid = { 'solver': [ 'liblinear', 'saga'],\n",
    "                      'penalty': ['l1', 'l2'], # NOTE: 'elasticnet' is only supported by 'saga' solver\n",
    "                      'C': np.arange(5,15),\n",
    "                      # number of iterations to converge (sometimes the default is not enough - and sometimes, it will never converge)\n",
    "                     }\n",
    "logi_reg = LogisticRegression()\n",
    "rand_search = RandomizedSearchCV(estimator = logi_reg, param_distributions=param_grid, cv=kfolds, n_iter=40,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,\n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "best_logi_reg_rand = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53a2ecbe-7bd6-402c-b325-96eec222576e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************\n",
      "Recall Score:     0.7454545454545455\n",
      "************************************\n",
      "Accuracy Score:   0.874831035414977\n",
      "Precision Score:  0.5593451568894953\n",
      "F1 Score:         0.6391270459859704\n",
      "************************************\n",
      "Confusion Matrix: [[2826  323]\n",
      " [ 140  410]]\n",
      "CPU times: total: 15.6 ms\n",
      "Wall time: 89 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# evaluate the model\n",
    "# predict on test data with default threshold\n",
    "y_pred = rand_search.predict(X_test)\n",
    "\n",
    "# adjust the threshold and predict again\n",
    "new_threshold = 0.3\n",
    "y_pred_thresh = (y_pred >= new_threshold).astype(int)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "# calculate evaluation metrics with adjusted threshold\n",
    "print(\"************************************\")\n",
    "print(f\"{'Recall Score:':18}{recall_score(y_test, y_pred_thresh)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Accuracy Score: ':18}{accuracy_score(y_test, y_pred_thresh)}\")\n",
    "print(f\"{'Precision Score: ':18}{precision_score(y_test, y_pred_thresh)}\")\n",
    "print(f\"{'F1 Score: ':18}{f1_score(y_test, y_pred_thresh)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Confusion Matrix: ':18}{confusion_matrix(y_test, y_pred_thresh)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9729b718",
   "metadata": {
    "id": "9729b718"
   },
   "outputs": [],
   "source": [
    "lr_rand_recall = recall_score(y_test, y_pred_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e391b499",
   "metadata": {
    "id": "e391b499"
   },
   "source": [
    "# 3.3 Fit a LogisticRegression model with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c3b2daa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7c3b2daa",
    "outputId": "7121c3f2-af01-40e8-9423-53380add0807"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "The best recall score is 0.745087801396314\n",
      "... with parameters: {'C': 7, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "CPU times: total: 172 ms\n",
      "Wall time: 580 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "penalty= rand_search.best_params_['penalty']\n",
    "solver =rand_search.best_params_['solver']\n",
    "C =rand_search.best_params_['C']\n",
    "param_grid = {\n",
    "    'C': [C+2,C,C-2],\n",
    "    'penalty': [penalty],\n",
    "    'solver': [solver]\n",
    "}\n",
    "\n",
    "logi_reg = LogisticRegression()\n",
    "grid_search = GridSearchCV(estimator = logi_reg, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "best_SVM_linear = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bda3a904",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bda3a904",
    "outputId": "c6cb4740-1b91-4a7b-a876-d04621a00811"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************\n",
      "Recall Score:     0.7454545454545455\n",
      "************************************\n",
      "Accuracy Score:   0.874831035414977\n",
      "Precision Score:  0.5593451568894953\n",
      "F1 Score:         0.6391270459859704\n",
      "************************************\n",
      "Confusion Matrix: [[2826  323]\n",
      " [ 140  410]]\n",
      "CPU times: total: 62.5 ms\n",
      "Wall time: 71.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# evaluate the model\n",
    "# predict on test data with default threshold\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# adjust the threshold and predict again\n",
    "new_threshold = 0.3\n",
    "y_pred_thresh = (y_pred >= new_threshold).astype(int)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "# calculate evaluation metrics with adjusted threshold\n",
    "print(\"************************************\")\n",
    "print(f\"{'Recall Score:':18}{recall_score(y_test, y_pred_thresh)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Accuracy Score: ':18}{accuracy_score(y_test, y_pred_thresh)}\")\n",
    "print(f\"{'Precision Score: ':18}{precision_score(y_test, y_pred_thresh)}\")\n",
    "print(f\"{'F1 Score: ':18}{f1_score(y_test, y_pred_thresh)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Confusion Matrix: ':18}{confusion_matrix(y_test, y_pred_thresh)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30a45c3a",
   "metadata": {
    "id": "30a45c3a"
   },
   "outputs": [],
   "source": [
    "lr_grid_recall = recall_score(y_test, y_pred_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818fead3",
   "metadata": {
    "id": "818fead3"
   },
   "source": [
    "# 3.4 Fit a SVM classification model using linear kernal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2211358b",
   "metadata": {
    "id": "2211358b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 14.5 s\n",
      "Wall time: 19.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "svm_lin_model = SVC(kernel=\"linear\")\n",
    "_ = svm_lin_model.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24e08b6f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "24e08b6f",
    "outputId": "8e5edcda-1da6-42c2-b19a-0286ef8e191e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************\n",
      "Recall Score:     0.730909090909091\n",
      "************************************\n",
      "Accuracy Score:   0.8799675587996756\n",
      "Precision Score:  0.5759312320916905\n",
      "F1 Score:         0.6442307692307692\n",
      "************************************\n",
      "Confusion Matrix: [[2853  296]\n",
      " [ 148  402]]\n",
      "CPU times: total: 922 ms\n",
      "Wall time: 1.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# evaluate the model\n",
    "# predict on test data with default threshold\n",
    "y_pred = svm_lin_model.predict(X_test)\n",
    "\n",
    "# adjust the threshold and predict again\n",
    "new_threshold = 0.3\n",
    "y_pred_thresh = (y_pred >= new_threshold).astype(int)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "# calculate evaluation metrics with adjusted threshold\n",
    "print(\"************************************\")\n",
    "print(f\"{'Recall Score:':18}{recall_score(y_test, y_pred_thresh)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Accuracy Score: ':18}{accuracy_score(y_test, y_pred_thresh)}\")\n",
    "print(f\"{'Precision Score: ':18}{precision_score(y_test, y_pred_thresh)}\")\n",
    "print(f\"{'F1 Score: ':18}{f1_score(y_test, y_pred_thresh)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Confusion Matrix: ':18}{confusion_matrix(y_test, y_pred_thresh)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "703785fa",
   "metadata": {
    "id": "703785fa"
   },
   "outputs": [],
   "source": [
    "svm_linear_default_recall = recall_score(y_test, y_pred_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625fdaf1",
   "metadata": {
    "id": "625fdaf1"
   },
   "source": [
    "# 3.5 Fit a SVM classification model using linear kernal with Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2689e9c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e2689e9c",
    "outputId": "d3991fee-c018-4d97-9f7c-1c2e5830646f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gopi Chand\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_search.py:305: UserWarning: The total space of parameters 4 is smaller than n_iter=20. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best recall score is 0.7401358743243035\n",
      "... with parameters: {'kernel': 'linear', 'C': 5}\n",
      "CPU times: total: 27.6 s\n",
      "Wall time: 1min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score_measure = \"recall\"\n",
    "kfolds = 2\n",
    "\n",
    "param_grid = {\n",
    "    'C': [5,10,15,20],\n",
    "    'kernel': ['linear'],\n",
    "    \n",
    "}\n",
    "\n",
    "svm = SVC()\n",
    "rand_search = RandomizedSearchCV(estimator =svm, param_distributions=param_grid, cv=kfolds, n_iter=20,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,\n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "best_SVM_linear = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0626ccba",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0626ccba",
    "outputId": "aa844c7d-bdff-4405-fd85-bcce9f51acab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************\n",
      "Recall Score:     0.730909090909091\n",
      "************************************\n",
      "Accuracy Score:   0.8799675587996756\n",
      "Precision Score:  0.5759312320916905\n",
      "F1 Score:         0.6442307692307692\n",
      "************************************\n",
      "Confusion Matrix: [[2853  296]\n",
      " [ 148  402]]\n",
      "CPU times: total: 1.08 s\n",
      "Wall time: 1.82 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# evaluate the model\n",
    "# predict on test data with default threshold\n",
    "y_pred = rand_search.predict(X_test)\n",
    "\n",
    "# adjust the threshold and predict again\n",
    "new_threshold = 0.3\n",
    "y_pred_thresh = (y_pred >= new_threshold).astype(int)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "# calculate evaluation metrics with adjusted threshold\n",
    "print(\"************************************\")\n",
    "print(f\"{'Recall Score:':18}{recall_score(y_test, y_pred_thresh)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Accuracy Score: ':18}{accuracy_score(y_test, y_pred_thresh)}\")\n",
    "print(f\"{'Precision Score: ':18}{precision_score(y_test, y_pred_thresh)}\")\n",
    "print(f\"{'F1 Score: ':18}{f1_score(y_test, y_pred_thresh)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Confusion Matrix: ':18}{confusion_matrix(y_test, y_pred_thresh)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "389d70d1",
   "metadata": {
    "id": "389d70d1"
   },
   "outputs": [],
   "source": [
    "svm_linear_rand_recall = recall_score(y_test, y_pred_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac5437e",
   "metadata": {
    "id": "eac5437e"
   },
   "source": [
    "# 3.6 Fit a SVM classification model using linear kernal with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5be2b4d9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5be2b4d9",
    "outputId": "eded996c-24d4-464c-a00c-02fb4b107b29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n",
      "The best recall score is 0.7401358743243035\n",
      "... with parameters: {'C': 7}\n",
      "CPU times: total: 30.9 s\n",
      "Wall time: 48.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score_measure = \"recall\"\n",
    "kfolds = 2\n",
    "\n",
    "C = rand_search.best_params_['C']\n",
    "\n",
    "param_grid = {\n",
    "    'C': [C+2,C,C-2]\n",
    "}\n",
    "\n",
    "svm_linear_model = SVC(kernel=\"linear\")\n",
    "grid_search = GridSearchCV(estimator = svm_linear_model, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "best_SVM_linear = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d2f3c76",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3d2f3c76",
    "outputId": "7483a2d2-fb14-4143-a2c3-dfc560558fe3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************\n",
      "Recall Score:     0.730909090909091\n",
      "************************************\n",
      "Accuracy Score:   0.8799675587996756\n",
      "Precision Score:  0.5759312320916905\n",
      "F1 Score:         0.6442307692307692\n",
      "************************************\n",
      "Confusion Matrix: [[2853  296]\n",
      " [ 148  402]]\n",
      "CPU times: total: 1 s\n",
      "Wall time: 1.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# evaluate the model\n",
    "# predict on test data with default threshold\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# adjust the threshold and predict again\n",
    "new_threshold = 0.3\n",
    "y_pred_thresh = (y_pred >= new_threshold).astype(int)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "# calculate evaluation metrics with adjusted threshold\n",
    "print(\"************************************\")\n",
    "print(f\"{'Recall Score:':18}{recall_score(y_test, y_pred_thresh)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Accuracy Score: ':18}{accuracy_score(y_test, y_pred_thresh)}\")\n",
    "print(f\"{'Precision Score: ':18}{precision_score(y_test, y_pred_thresh)}\")\n",
    "print(f\"{'F1 Score: ':18}{f1_score(y_test, y_pred_thresh)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Confusion Matrix: ':18}{confusion_matrix(y_test, y_pred_thresh)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf60f7de",
   "metadata": {
    "id": "bf60f7de"
   },
   "outputs": [],
   "source": [
    "svm_linear_grid_recall = recall_score(y_test, y_pred_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fef810",
   "metadata": {
    "id": "96fef810"
   },
   "source": [
    "# 3.7 Fit a SVM classification model using rbf kernal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dd9db041",
   "metadata": {
    "id": "dd9db041"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 9.27 s\n",
      "Wall time: 9.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "svm_rbf_model = SVC(kernel=\"rbf\")\n",
    "_ = svm_rbf_model.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c8e89a3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4c8e89a3",
    "outputId": "7812886e-c619-4c5c-aa1d-0c1324ac758e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************\n",
      "Recall Score:     0.7490909090909091\n",
      "************************************\n",
      "Accuracy Score:   0.8675317653419843\n",
      "Precision Score:  0.5392670157068062\n",
      "F1 Score:         0.6270928462709285\n",
      "************************************\n",
      "Confusion Matrix: [[2797  352]\n",
      " [ 138  412]]\n",
      "CPU times: total: 3.39 s\n",
      "Wall time: 3.43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# evaluate the model\n",
    "# predict on test data with default threshold\n",
    "y_pred = svm_rbf_model.predict(X_test)\n",
    "\n",
    "# adjust the threshold and predict again\n",
    "new_threshold = 0.3\n",
    "y_pred_thresh = (y_pred >= new_threshold).astype(int)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "# calculate evaluation metrics with adjusted threshold\n",
    "print(\"************************************\")\n",
    "print(f\"{'Recall Score:':18}{recall_score(y_test, y_pred_thresh)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Accuracy Score: ':18}{accuracy_score(y_test, y_pred_thresh)}\")\n",
    "print(f\"{'Precision Score: ':18}{precision_score(y_test, y_pred_thresh)}\")\n",
    "print(f\"{'F1 Score: ':18}{f1_score(y_test, y_pred_thresh)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Confusion Matrix: ':18}{confusion_matrix(y_test, y_pred_thresh)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5312312b",
   "metadata": {
    "id": "5312312b"
   },
   "outputs": [],
   "source": [
    "svm_rbf_default_recall = recall_score(y_test, y_pred_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e538be",
   "metadata": {
    "id": "b0e538be"
   },
   "source": [
    "# 3.8 Fit a SVM classification model using rbf kernal with Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eed86355",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eed86355",
    "outputId": "0d69b390-a0f1-4ee2-cc9d-6cbaed5142fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gopi Chand\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_search.py:305: UserWarning: The total space of parameters 10 is smaller than n_iter=12. Running 10 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best recall score is 0.8127322080572094\n",
      "... with parameters: {'kernel': 'rbf', 'C': 14}\n",
      "CPU times: total: 9.22 s\n",
      "Wall time: 53.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score_measure = \"recall\"\n",
    "kfolds = 2\n",
    "\n",
    "param_grid = {\n",
    "    'C': np.arange(5,15),\n",
    "    'kernel': ['rbf'],\n",
    "    \n",
    "}\n",
    "\n",
    "svm = SVC()\n",
    "rand_search = RandomizedSearchCV(estimator =svm, param_distributions=param_grid, cv=kfolds, n_iter=12,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,\n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "best_SVM_linear = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "09092e1c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "09092e1c",
    "outputId": "3eb6f306-83a3-4cc9-98b6-a0cc18b94c9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************\n",
      "Recall Score:     0.7345454545454545\n",
      "************************************\n",
      "Accuracy Score:   0.8675317653419843\n",
      "Precision Score:  0.5401069518716578\n",
      "F1 Score:         0.6224961479198767\n",
      "************************************\n",
      "Confusion Matrix: [[2805  344]\n",
      " [ 146  404]]\n",
      "CPU times: total: 2.47 s\n",
      "Wall time: 4.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# evaluate the model\n",
    "# predict on test data with default threshold\n",
    "y_pred = rand_search.predict(X_test)\n",
    "\n",
    "# adjust the threshold and predict again\n",
    "new_threshold = 0.3\n",
    "y_pred_thresh = (y_pred >= new_threshold).astype(int)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "# calculate evaluation metrics with adjusted threshold\n",
    "print(\"************************************\")\n",
    "print(f\"{'Recall Score:':18}{recall_score(y_test, y_pred_thresh)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Accuracy Score: ':18}{accuracy_score(y_test, y_pred_thresh)}\")\n",
    "print(f\"{'Precision Score: ':18}{precision_score(y_test, y_pred_thresh)}\")\n",
    "print(f\"{'F1 Score: ':18}{f1_score(y_test, y_pred_thresh)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Confusion Matrix: ':18}{confusion_matrix(y_test, y_pred_thresh)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e288ee4",
   "metadata": {
    "id": "8e288ee4"
   },
   "outputs": [],
   "source": [
    "svm_rbf_rand_recall = recall_score(y_test, y_pred_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c9168a",
   "metadata": {
    "id": "d5c9168a"
   },
   "source": [
    "# 3.9 Fit a SVM classification model using rbf kernal with Grid Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b88a3aa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2b88a3aa",
    "outputId": "4e83e5e5-9eb2-4ed8-c6b3-9a2445e7e40d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "The best recall score is 0.8180924999716467\n",
      "... with parameters: {'C': 15}\n",
      "CPU times: total: 12.1 s\n",
      "Wall time: 37.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score_measure = \"recall\"\n",
    "kfolds = 3\n",
    "\n",
    "C = rand_search.best_params_['C']\n",
    "\n",
    "param_grid = {\n",
    "    'C': [C+1,C,C-1]\n",
    "}\n",
    "\n",
    "svm_linear_model = SVC(kernel=\"rbf\")\n",
    "grid_search = GridSearchCV(estimator = svm_linear_model, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "best_SVM_linear = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a6a1afeb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a6a1afeb",
    "outputId": "21430ea5-648e-4e2f-d45f-4c0ee43a2863"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************\n",
      "Recall Score:     0.7327272727272728\n",
      "************************************\n",
      "Accuracy Score:   0.8678021086780211\n",
      "Precision Score:  0.5409395973154363\n",
      "F1 Score:         0.6223938223938225\n",
      "************************************\n",
      "Confusion Matrix: [[2807  342]\n",
      " [ 147  403]]\n",
      "CPU times: total: 3.11 s\n",
      "Wall time: 3.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# evaluate the model\n",
    "# predict on test data with default threshold\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# adjust the threshold and predict again\n",
    "new_threshold = 0.3\n",
    "y_pred_thresh = (y_pred >= new_threshold).astype(int)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "# calculate evaluation metrics with adjusted threshold\n",
    "print(\"************************************\")\n",
    "print(f\"{'Recall Score:':18}{recall_score(y_test, y_pred_thresh)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Accuracy Score: ':18}{accuracy_score(y_test, y_pred_thresh)}\")\n",
    "print(f\"{'Precision Score: ':18}{precision_score(y_test, y_pred_thresh)}\")\n",
    "print(f\"{'F1 Score: ':18}{f1_score(y_test, y_pred_thresh)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Confusion Matrix: ':18}{confusion_matrix(y_test, y_pred_thresh)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "56882aef",
   "metadata": {
    "id": "56882aef"
   },
   "outputs": [],
   "source": [
    "svm_rbf_grid_recall = recall_score(y_test, y_pred_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace282b8",
   "metadata": {
    "id": "ace282b8"
   },
   "source": [
    "# 3.10 Fit a SVM classification model using polynomial kernal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3b4b79b0",
   "metadata": {
    "id": "3b4b79b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 47.4 s\n",
      "Wall time: 48.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "svm_poly_model= SVC(kernel=\"poly\", degree=3, coef0=1, C=10)\n",
    "_ = svm_poly_model.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "623d72f3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "623d72f3",
    "outputId": "2f5bd56c-0832-42e2-dabc-af4e1356f74b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************\n",
      "Recall Score:     0.7345454545454545\n",
      "************************************\n",
      "Accuracy Score:   0.8772641254393079\n",
      "Precision Score:  0.5674157303370787\n",
      "F1 Score:         0.6402535657686212\n",
      "************************************\n",
      "Confusion Matrix: [[2841  308]\n",
      " [ 146  404]]\n",
      "CPU times: total: 969 ms\n",
      "Wall time: 1.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# evaluate the model\n",
    "# predict on test data with default threshold\n",
    "y_pred =svm_poly_model.predict(X_test)\n",
    "\n",
    "# adjust the threshold and predict again\n",
    "new_threshold = 0.3\n",
    "y_pred_thresh = (y_pred >= new_threshold).astype(int)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "# calculate evaluation metrics with adjusted threshold\n",
    "print(\"************************************\")\n",
    "print(f\"{'Recall Score:':18}{recall_score(y_test, y_pred_thresh)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Accuracy Score: ':18}{accuracy_score(y_test, y_pred_thresh)}\")\n",
    "print(f\"{'Precision Score: ':18}{precision_score(y_test, y_pred_thresh)}\")\n",
    "print(f\"{'F1 Score: ':18}{f1_score(y_test, y_pred_thresh)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Confusion Matrix: ':18}{confusion_matrix(y_test, y_pred_thresh)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f7d49355",
   "metadata": {
    "id": "f7d49355"
   },
   "outputs": [],
   "source": [
    "svm_poly_default_recall = recall_score(y_test, y_pred_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd131c4",
   "metadata": {
    "id": "dbd131c4"
   },
   "source": [
    "# 3.11 Fit a SVM classification model using Polynomial kernal with Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f94f3c45",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f94f3c45",
    "outputId": "01a2c2aa-70de-4142-ab17-4789bdcfb673"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
      "The best recall score is 0.8277185980902186\n",
      "... with parameters: {'degree': 4, 'coef0': 4, 'C': 15}\n",
      "CPU times: total: 21min 41s\n",
      "Wall time: 29min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score_measure = \"recall\"\n",
    "kfolds = 2\n",
    "\n",
    "param_rand = {\n",
    "    'C': [10,15],\n",
    "    'degree': [3,4],\n",
    "    'coef0': [4,5]\n",
    "\n",
    "}\n",
    "\n",
    "svm_poly_model = SVC(kernel=\"poly\")\n",
    "rand_search = RandomizedSearchCV(estimator = svm_poly_model, param_distributions=param_rand, cv=kfolds, n_iter=5,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train,np.ravel(y_train))\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "best_SVM_poly = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3889ce30",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3889ce30",
    "outputId": "40ccf866-35ed-48cd-90c1-3470f3d87f24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************\n",
      "Recall Score:     0.7163636363636363\n",
      "************************************\n",
      "Accuracy Score:   0.8629359286293593\n",
      "Precision Score:  0.5288590604026846\n",
      "F1 Score:         0.6084942084942085\n",
      "************************************\n",
      "Confusion Matrix: [[2798  351]\n",
      " [ 156  394]]\n",
      "CPU times: total: 984 ms\n",
      "Wall time: 977 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# evaluate the model\n",
    "# predict on test data with default threshold\n",
    "y_pred = rand_search.predict(X_test)\n",
    "\n",
    "# adjust the threshold and predict again\n",
    "new_threshold = 0.3\n",
    "y_pred_thresh = (y_pred >= new_threshold).astype(int)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "# calculate evaluation metrics with adjusted threshold\n",
    "print(\"************************************\")\n",
    "print(f\"{'Recall Score:':18}{recall_score(y_test, y_pred_thresh)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Accuracy Score: ':18}{accuracy_score(y_test, y_pred_thresh)}\")\n",
    "print(f\"{'Precision Score: ':18}{precision_score(y_test, y_pred_thresh)}\")\n",
    "print(f\"{'F1 Score: ':18}{f1_score(y_test, y_pred_thresh)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Confusion Matrix: ':18}{confusion_matrix(y_test, y_pred_thresh)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "59e97092",
   "metadata": {
    "id": "59e97092"
   },
   "outputs": [],
   "source": [
    "svm_poly_rand_recall = recall_score(y_test, y_pred_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716a3af2",
   "metadata": {
    "id": "716a3af2"
   },
   "source": [
    "# 3.12 Fit a SVM classification model using Polynomial kernal with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7ced13a5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ced13a5",
    "outputId": "f9db40d6-2f26-4e65-983d-f20527f7d530"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n",
      "The best recall score is 0.8292311359263504\n",
      "... with parameters: {'C': 16, 'coef0': 4, 'degree': 4}\n",
      "CPU times: total: 19min 26s\n",
      "Wall time: 27min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score_measure = \"recall\"\n",
    "kfolds = 2\n",
    "\n",
    "degree = rand_search.best_params_['degree']\n",
    "coef0 = rand_search.best_params_['coef0']\n",
    "C = rand_search.best_params_['C']\n",
    "param_grid = {\n",
    "    'C': [C-1,C,C+1],\n",
    "    'degree': [degree],\n",
    "    'coef0': [coef0],\n",
    "}\n",
    "\n",
    "svm_poly_model = SVC(kernel=\"poly\")\n",
    "grid_search = GridSearchCV(estimator = svm_poly_model, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "best_SVM_poly = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "27f462da",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "27f462da",
    "outputId": "b11de954-cd97-4742-d012-6b0ef696ae25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************\n",
      "Recall Score:     0.7163636363636363\n",
      "************************************\n",
      "Accuracy Score:   0.8629359286293593\n",
      "Precision Score:  0.5288590604026846\n",
      "F1 Score:         0.6084942084942085\n",
      "************************************\n",
      "Confusion Matrix: [[2798  351]\n",
      " [ 156  394]]\n",
      "CPU times: total: 891 ms\n",
      "Wall time: 1.04 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# evaluate the model\n",
    "# predict on test data with default threshold\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# adjust the threshold and predict again\n",
    "new_threshold = 0.3\n",
    "y_pred_thresh = (y_pred >= new_threshold).astype(int)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "# calculate evaluation metrics with adjusted threshold\n",
    "print(\"************************************\")\n",
    "print(f\"{'Recall Score:':18}{recall_score(y_test, y_pred_thresh)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Accuracy Score: ':18}{accuracy_score(y_test, y_pred_thresh)}\")\n",
    "print(f\"{'Precision Score: ':18}{precision_score(y_test, y_pred_thresh)}\")\n",
    "print(f\"{'F1 Score: ':18}{f1_score(y_test, y_pred_thresh)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Confusion Matrix: ':18}{confusion_matrix(y_test, y_pred_thresh)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4ab43e39",
   "metadata": {
    "id": "4ab43e39"
   },
   "outputs": [],
   "source": [
    "svm_poly_grid_recall = recall_score(y_test, y_pred_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc78042",
   "metadata": {
    "id": "ecc78042"
   },
   "source": [
    "# 3.13 Fit a DTree classification model using defaults (unconstrained tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9a75ee02",
   "metadata": {
    "id": "9a75ee02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 93.8 ms\n",
      "Wall time: 116 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dtree = DecisionTreeClassifier()\n",
    "_=dtree.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2d71f60e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2d71f60e",
    "outputId": "d15c3acd-6866-4f61-90bb-7f9555cdc678"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************\n",
      "Recall Score:     0.5636363636363636\n",
      "************************************\n",
      "Accuracy Score:   0.8613138686131386\n",
      "Precision Score:  0.5317324185248714\n",
      "F1 Score:         0.5472197705207414\n",
      "************************************\n",
      "Confusion Matrix: [[2876  273]\n",
      " [ 240  310]]\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 47 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# evaluate the model\n",
    "# predict on test data with default threshold\n",
    "y_pred = dtree.predict(X_test)\n",
    "\n",
    "# adjust the threshold and predict again\n",
    "new_threshold = 0.3\n",
    "y_pred_thresh = (y_pred >= new_threshold).astype(int)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "# calculate evaluation metrics with adjusted threshold\n",
    "print(\"************************************\")\n",
    "print(f\"{'Recall Score:':18}{recall_score(y_test, y_pred_thresh)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Accuracy Score: ':18}{accuracy_score(y_test, y_pred_thresh)}\")\n",
    "print(f\"{'Precision Score: ':18}{precision_score(y_test, y_pred_thresh)}\")\n",
    "print(f\"{'F1 Score: ':18}{f1_score(y_test, y_pred_thresh)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Confusion Matrix: ':18}{confusion_matrix(y_test, y_pred_thresh)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e54bef4f",
   "metadata": {
    "id": "e54bef4f"
   },
   "outputs": [],
   "source": [
    "dtree_default_recall = recall_score(y_test, y_pred_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1a0925",
   "metadata": {
    "id": "6b1a0925"
   },
   "source": [
    "# 3.14 Fit a Decision Tree Classifier model with Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "68285a7b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "68285a7b",
    "outputId": "0bbc0787-fdc1-4723-d348-eb99a0673ac1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best parameters found:  {'min_samples_split': 2, 'min_samples_leaf': 125, 'min_impurity_decrease': 0.0006, 'max_leaf_nodes': 2567, 'max_depth': 1667, 'criterion': 'entropy'}\n",
      "CPU times: total: 1.2 s\n",
      "Wall time: 6.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Criterion used to guide data splits\n",
    "criterion = ['gini', 'entropy']\n",
    "\n",
    "# Maximum number of levels in tree. If None, then nodes are expanded until all leaves are pure or until all \n",
    "# leaves contain less than min_samples_split samples.\n",
    "# default = None\n",
    "max_depth = [int(x) for x in np.linspace(1, 5000, 25)]\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "# default is 2\n",
    "min_samples_split = [int(x) for x in np.linspace(2, 5000, 25)]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "# default = 1 \n",
    "min_samples_leaf = [int(x) for x in np.linspace(1, 500, 5)]\n",
    "\n",
    "# max_leaf_nodes  - Grow trees with max_leaf_nodes in best-first fashion.\n",
    "# If None then unlimited number of leaf nodes.\n",
    "# default=None \n",
    "max_leaf_nodes = [int(x) for x in np.linspace(2, len(y_test), 50)]\n",
    "max_leaf_nodes.append(None)\n",
    "\n",
    "# min_impurity_decrease - A node will be split if this split induces a decrease of the impurity greater than or equal to this value.\n",
    "# default=0.0\n",
    "min_impurity_decrease = [x for x in np.arange(0.0, 0.01, 0.0001).round(5)]\n",
    "\n",
    "# Create the random grid\n",
    "param_grid_random = { 'criterion': criterion,\n",
    "                      'max_depth': max_depth,\n",
    "                      'min_samples_split': min_samples_split,\n",
    "                      'min_samples_leaf' : min_samples_leaf,\n",
    "                      'max_leaf_nodes' : max_leaf_nodes,\n",
    "                      'min_impurity_decrease' : min_impurity_decrease,\n",
    "                     }\n",
    "\n",
    "best_random_search_model = RandomizedSearchCV(\n",
    "        estimator=DecisionTreeClassifier(), \n",
    "        scoring='recall', \n",
    "        param_distributions=param_grid_random, \n",
    "        n_iter = 100, random_state=1,\n",
    "        cv=5, \n",
    "        verbose=1, \n",
    "        n_jobs = -1\n",
    "    )\n",
    "_ = best_random_search_model.fit(X_train, np.ravel(y_train))\n",
    "random_search_best_params = best_random_search_model.best_params_\n",
    "print('Best parameters found: ', random_search_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "51243e3b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "51243e3b",
    "outputId": "3f6b3fb2-a5af-46bd-e54b-1909399eab54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************\n",
      "Recall Score:     0.8490909090909091\n",
      "************************************\n",
      "Accuracy Score:   0.8288726682887266\n",
      "Precision Score:  0.4591937069813176\n",
      "F1 Score:         0.5960433950223356\n",
      "************************************\n",
      "Confusion Matrix: [[2599  550]\n",
      " [  83  467]]\n",
      "CPU times: total: 31.2 ms\n",
      "Wall time: 85.2 ms\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "# evaluate the model\n",
    "# predict on test data with default threshold\n",
    "y_pred = best_random_search_model.predict(X_test)\n",
    "\n",
    "# adjust the threshold and predict again\n",
    "new_threshold = 0.3\n",
    "y_pred_thresh = (y_pred >= new_threshold).astype(int)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "# calculate evaluation metrics with adjusted threshold\n",
    "print(\"************************************\")\n",
    "print(f\"{'Recall Score:':18}{recall_score(y_test, y_pred_thresh)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Accuracy Score: ':18}{accuracy_score(y_test, y_pred_thresh)}\")\n",
    "print(f\"{'Precision Score: ':18}{precision_score(y_test, y_pred_thresh)}\")\n",
    "print(f\"{'F1 Score: ':18}{f1_score(y_test, y_pred_thresh)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Confusion Matrix: ':18}{confusion_matrix(y_test, y_pred_thresh)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c92786e1",
   "metadata": {
    "id": "c92786e1"
   },
   "outputs": [],
   "source": [
    "dtree_rand_recall = recall_score(y_test, y_pred_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f451ca2e",
   "metadata": {
    "id": "f451ca2e"
   },
   "source": [
    "# 3.15 Fit a Decision Tree Classifier model with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f05574fd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f05574fd",
    "outputId": "25575fa3-42a1-40b1-9275-eecbdb99b433"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2048 candidates, totalling 10240 fits\n",
      "Best parameters found:  {'criterion': 'entropy', 'max_depth': 1663, 'max_leaf_nodes': 2563, 'min_impurity_decrease': 0.0008, 'min_samples_leaf': 125, 'min_samples_split': 2}\n",
      "CPU times: total: 28.7 s\n",
      "Wall time: 2min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "plus_minus = 4\n",
    "increment = 2\n",
    "\n",
    "param_grid = { 'min_samples_split': [x for x in range(random_search_best_params['min_samples_split']-plus_minus, random_search_best_params['min_samples_split']+plus_minus,2) if x >= 2],       \n",
    "              'min_samples_leaf': [x for x in range(random_search_best_params['min_samples_leaf']-plus_minus , random_search_best_params['min_samples_leaf']+plus_minus,2) if x > 0],\n",
    "              'min_impurity_decrease': [x for x in np.arange(random_search_best_params['min_impurity_decrease']-0.001, random_search_best_params['min_impurity_decrease']+0.001,.0001).round(5) if x >= 0.000],\n",
    "              'max_leaf_nodes':[x for x in range(random_search_best_params['max_leaf_nodes']-plus_minus , random_search_best_params['max_leaf_nodes']+plus_minus, 2) if x > 1],  \n",
    "              'max_depth': [x for x in range(random_search_best_params['max_depth']-plus_minus , random_search_best_params['max_depth']+plus_minus, 2) if x > 1],\n",
    "              'criterion': [random_search_best_params['criterion']]\n",
    "              }\n",
    "\n",
    "best_grid_search_model = GridSearchCV(estimator=DecisionTreeClassifier(), \n",
    "                                    scoring='recall', param_grid=param_grid, cv=5, verbose=1,  n_jobs = -1)\n",
    "_ = best_grid_search_model.fit(X_train, y_train)\n",
    "print('Best parameters found: ', best_grid_search_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ca581926",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ca581926",
    "outputId": "886c9f8e-565c-4666-fdaa-f45ac5a6b96f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************\n",
      "Recall Score:     0.8345454545454546\n",
      "************************************\n",
      "Accuracy Score:   0.8450932684509327\n",
      "Precision Score:  0.487778958554729\n",
      "F1 Score:         0.6156941649899396\n",
      "************************************\n",
      "Confusion Matrix: [[2667  482]\n",
      " [  91  459]]\n",
      "CPU times: total: 46.9 ms\n",
      "Wall time: 63.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# evaluate the model\n",
    "# predict on test data with default threshold\n",
    "y_pred = best_grid_search_model.predict(X_test)\n",
    "\n",
    "# adjust the threshold and predict again\n",
    "new_threshold = 0.3\n",
    "y_pred_thresh = (y_pred >= new_threshold).astype(int)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "# calculate evaluation metrics with adjusted threshold\n",
    "print(\"************************************\")\n",
    "print(f\"{'Recall Score:':18}{recall_score(y_test, y_pred_thresh)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Accuracy Score: ':18}{accuracy_score(y_test, y_pred_thresh)}\")\n",
    "print(f\"{'Precision Score: ':18}{precision_score(y_test, y_pred_thresh)}\")\n",
    "print(f\"{'F1 Score: ':18}{f1_score(y_test, y_pred_thresh)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Confusion Matrix: ':18}{confusion_matrix(y_test, y_pred_thresh)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1fba875e",
   "metadata": {
    "id": "1fba875e"
   },
   "outputs": [],
   "source": [
    "dtree_grid_recall = recall_score(y_test, y_pred_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3a4fbf",
   "metadata": {},
   "source": [
    "# 3.16 Neural Net with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "feac23ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 45.1 s\n",
      "Wall time: 2min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ann = MLPClassifier(hidden_layer_sizes=(60,50,40), solver='adam', max_iter=2000)\n",
    "_ = ann.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2ac32d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************\n",
      "Recall Score:     0.6290909090909091\n",
      "************************************\n",
      "Accuracy Score:   0.8734793187347932\n",
      "Precision Score:  0.5672131147540984\n",
      "F1 Score:         0.5965517241379311\n",
      "************************************\n",
      "Confusion Matrix: [[2885  264]\n",
      " [ 204  346]]\n",
      "CPU times: total: 266 ms\n",
      "Wall time: 104 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# evaluate the model\n",
    "# predict on test data with default threshold\n",
    "y_pred = ann.predict(X_test)\n",
    "\n",
    "# adjust the threshold and predict again\n",
    "new_threshold = 0.3\n",
    "y_pred_thresh = (y_pred >= new_threshold).astype(int)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "# calculate evaluation metrics with adjusted threshold\n",
    "print(\"************************************\")\n",
    "print(f\"{'Recall Score:':18}{recall_score(y_test, y_pred_thresh)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Accuracy Score: ':18}{accuracy_score(y_test, y_pred_thresh)}\")\n",
    "print(f\"{'Precision Score: ':18}{precision_score(y_test, y_pred_thresh)}\")\n",
    "print(f\"{'F1 Score: ':18}{f1_score(y_test, y_pred_thresh)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Confusion Matrix: ':18}{confusion_matrix(y_test, y_pred_thresh)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e25424c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ann_default_recall = recall_score(y_test, y_pred_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77a9c8b",
   "metadata": {},
   "source": [
    "# 3.17 NN With RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e5c550a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "{'solver': 'adam', 'max_iter': 2000, 'learning_rate_init': 0.01, 'learning_rate': 'constant', 'hidden_layer_sizes': (60, 40, 20), 'alpha': 0, 'activation': 'tanh'}\n",
      "CPU times: total: 6.33 s\n",
      "Wall time: 16min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [ (50,), (70,),(50,30), (40,20), (60,40, 20), (70,50,40)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'alpha': [0, .2, .5, .7, 1],\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1, 0.2, 0.5],\n",
    "    'max_iter': [2000]\n",
    "}\n",
    "\n",
    "ann = MLPClassifier()\n",
    "random_search = RandomizedSearchCV(estimator = ann, param_distributions=param_grid, cv=kfolds, n_iter=100,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = random_search.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "bestRecallANN = random_search.best_estimator_\n",
    "\n",
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eaace1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************\n",
      "Recall Score:     0.649090909090909\n",
      "************************************\n",
      "Accuracy Score:   0.8353609083536091\n",
      "Precision Score:  0.46183699870633893\n",
      "F1 Score:         0.5396825396825397\n",
      "************************************\n",
      "Confusion Matrix: [[2733  416]\n",
      " [ 193  357]]\n",
      "CPU times: total: 46.9 ms\n",
      "Wall time: 65.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# evaluate the model\n",
    "# predict on test data with default threshold\n",
    "y_pred = bestRecallANN.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "# calculate evaluation metrics with adjusted threshold\n",
    "print(\"************************************\")\n",
    "print(f\"{'Recall Score:':18}{recall_score(y_test, y_pred)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Accuracy Score: ':18}{accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"{'Precision Score: ':18}{precision_score(y_test, y_pred)}\")\n",
    "print(f\"{'F1 Score: ':18}{f1_score(y_test, y_pred)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Confusion Matrix: ':18}{confusion_matrix(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3b6a338f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_random_recall = recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c00b28c",
   "metadata": {},
   "source": [
    "# 3.18 NN With GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a2d2a68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "{'activation': 'tanh', 'alpha': 1, 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.15, 'max_iter': 5000, 'solver': 'adam'}\n",
      "CPU times: total: 4.22 s\n",
      "Wall time: 4min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [ (30,), (50,), (70,), (90,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['adam'],\n",
    "    'alpha': [.5, .7, 1],\n",
    "    'learning_rate': ['adaptive', 'invscaling'],\n",
    "    'learning_rate_init': [0.005, 0.01, 0.15],\n",
    "    'max_iter': [5000]\n",
    "}\n",
    "\n",
    "ann = MLPClassifier()\n",
    "grid_search = GridSearchCV(estimator = ann, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "bestRecallANN = grid_search.best_estimator_\n",
    "\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e5ca2367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************\n",
      "Recall Score:     0.8545454545454545\n",
      "************************************\n",
      "Accuracy Score:   0.7764260610975939\n",
      "Precision Score:  0.3861955628594905\n",
      "F1 Score:         0.5319750990379174\n",
      "************************************\n",
      "Confusion Matrix: [[2402  747]\n",
      " [  80  470]]\n",
      "CPU times: total: 46.9 ms\n",
      "Wall time: 55.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# evaluate the model\n",
    "# predict on test data with default threshold\n",
    "y_pred = bestRecallANN.predict(X_test)\n",
    "\n",
    "# adjust the threshold and predict again\n",
    "new_threshold = 0.3\n",
    "y_pred_thresh = (y_pred >= new_threshold).astype(int)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "# calculate evaluation metrics with adjusted threshold\n",
    "print(\"************************************\")\n",
    "print(f\"{'Recall Score:':18}{recall_score(y_test, y_pred_thresh)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Accuracy Score: ':18}{accuracy_score(y_test, y_pred_thresh)}\")\n",
    "print(f\"{'Precision Score: ':18}{precision_score(y_test, y_pred_thresh)}\")\n",
    "print(f\"{'F1 Score: ':18}{f1_score(y_test, y_pred_thresh)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Confusion Matrix: ':18}{confusion_matrix(y_test, y_pred_thresh)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "58f938e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_grid_recall = recall_score(y_test, y_pred_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aec72fd-b7e3-4c92-b31d-d86e373b5336",
   "metadata": {},
   "source": [
    "# 3.19 Deep Network using Random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e9293479-9d89-485e-a935-8bff22044c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8a77602f-3f00-407b-90fa-7ff1175de4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def build_clf(meta, hidden_layer_sizes, dropout):\n",
    "    n_features_in_ = meta[\"n_features_in_\"]\n",
    "    n_classes_ = meta[\"n_classes_\"]\n",
    "    target_encoder_ = meta[\"target_encoder_\"]\n",
    "    \n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(keras.layers.Input(shape=n_features_in_)),\n",
    "    #for hidden_layer_size in hidden_layer_sizes:\n",
    "    for hidden_layer_size in hidden_layer_sizes:\n",
    "        model.add(keras.layers.Dense(hidden_layer_size, \n",
    "            kernel_initializer= tf.keras.initializers.GlorotUniform(), \n",
    "            bias_initializer=keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None), \n",
    "            activation=\"relu\"))\n",
    "        model.add(keras.layers.Dropout(dropout))\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    #though you could return a compiled model, it's not necessary, and would result in the loss of these\n",
    "    # parameters in the tune process - as they would be 'hard coded'\n",
    "    # model.compile(loss = 'sparse_categorical_crossentropy', metrics = ['accuracy']) \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0147ffdb-5898-442b-b207-33a0bea8f8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 78.1 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': <function __main__.build_clf(meta, hidden_layer_sizes, dropout)>,\n",
       " 'build_fn': None,\n",
       " 'warm_start': False,\n",
       " 'random_state': None,\n",
       " 'optimizer': keras.optimizers.optimizer_v2.adam.Adam,\n",
       " 'loss': None,\n",
       " 'metrics': None,\n",
       " 'batch_size': None,\n",
       " 'validation_batch_size': None,\n",
       " 'verbose': 1,\n",
       " 'callbacks': None,\n",
       " 'validation_split': 0.0,\n",
       " 'shuffle': True,\n",
       " 'run_eagerly': False,\n",
       " 'epochs': 1,\n",
       " 'hidden_layer_sizes': 13,\n",
       " 'dropout': 0.5,\n",
       " 'optimizer__learning_rate': 0.0001,\n",
       " 'class_weight': None}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# If you don't have the following installed, from command line '!pip install scikeras'\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "keras_clf = KerasClassifier(\n",
    "    model=build_clf,\n",
    "    hidden_layer_sizes=13,\n",
    "    dropout=0.5,\n",
    "    optimizer=keras.optimizers.Adam,\n",
    "    optimizer__learning_rate=0.0001\n",
    ")\n",
    "keras_clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c6c7f106-1c58-4e0d-b23c-b215b410f6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': <function __main__.build_clf(meta, hidden_layer_sizes, dropout)>,\n",
       " 'build_fn': None,\n",
       " 'warm_start': False,\n",
       " 'random_state': None,\n",
       " 'optimizer': keras.optimizers.optimizer_v2.adam.Adam,\n",
       " 'loss': None,\n",
       " 'metrics': None,\n",
       " 'batch_size': None,\n",
       " 'validation_batch_size': None,\n",
       " 'verbose': 1,\n",
       " 'callbacks': None,\n",
       " 'validation_split': 0.0,\n",
       " 'shuffle': True,\n",
       " 'run_eagerly': False,\n",
       " 'epochs': 1,\n",
       " 'hidden_layer_sizes': 13,\n",
       " 'dropout': 0.5,\n",
       " 'optimizer__learning_rate': 0.0001,\n",
       " 'class_weight': None}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "params = {\n",
    "    \n",
    "    # the following are model parameters, and therefore must be defined as parameters in the KarasClassifier, and then in the build_clf function\n",
    "    'model__hidden_layer_sizes': [(70,),(90, ), (100,), (100, 90)], # this will require KarasClassifier and build_clf to have hidden_layer_sizes parameter set\n",
    "    'model__dropout': [0, 0.1], # this will require KarasClassifier and build_clf to have hidden_layer_sizes parameter set\n",
    "    \n",
    "    # the following are 'fit' parameters, the scikeras wrapper provides these parameters. These are passed to the 'model.fit' method for each fit of the model\n",
    "    'batch_size':[20, 60, 100],\n",
    "    'epochs':[10],\n",
    "    'optimizer':['adam','sgd'],\n",
    "    'loss':['binary_crossentropy'],\n",
    "    \n",
    "    # this is added to the optimizer \n",
    "    'optimizer__learning_rate': [0.0001, 0.001, 0.01]\n",
    "\n",
    "}\n",
    "keras_clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5c855ca7-6d7b-4aea-8654-1d3a2950d604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "162/162 [==============================] - 2s 5ms/step - loss: 0.6661\n",
      "Epoch 2/10\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.6478\n",
      "Epoch 3/10\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.6341\n",
      "Epoch 4/10\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.6194\n",
      "Epoch 5/10\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.6108\n",
      "Epoch 6/10\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.5985\n",
      "Epoch 7/10\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.5890\n",
      "Epoch 8/10\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.5825\n",
      "Epoch 9/10\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.5726\n",
      "Epoch 10/10\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.5662\n",
      "81/81 [==============================] - 0s 3ms/step\n",
      "Epoch 1/10\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.6748\n",
      "Epoch 2/10\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.6594\n",
      "Epoch 3/10\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.6439\n",
      "Epoch 4/10\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.6279\n",
      "Epoch 5/10\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.6168\n",
      "Epoch 6/10\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.6052\n",
      "Epoch 7/10\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.5948\n",
      "Epoch 8/10\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.5846\n",
      "Epoch 9/10\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.5768\n",
      "Epoch 10/10\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.5690\n",
      "81/81 [==============================] - 0s 3ms/step\n",
      "Epoch 1/10\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.7464\n",
      "Epoch 2/10\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.6899\n",
      "Epoch 3/10\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.6577\n",
      "Epoch 4/10\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.6349\n",
      "Epoch 5/10\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.6201\n",
      "Epoch 6/10\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.6070\n",
      "Epoch 7/10\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.5926\n",
      "Epoch 8/10\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.5835\n",
      "Epoch 9/10\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.5730\n",
      "Epoch 10/10\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.5647\n",
      "81/81 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "162/162 [==============================] - 2s 5ms/step - loss: 0.4609\n",
      "Epoch 2/10\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.4021\n",
      "Epoch 3/10\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.3886\n",
      "Epoch 4/10\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.3799\n",
      "Epoch 5/10\n",
      "162/162 [==============================] - 1s 6ms/step - loss: 0.3745\n",
      "Epoch 6/10\n",
      "162/162 [==============================] - 1s 6ms/step - loss: 0.3725\n",
      "Epoch 7/10\n",
      "162/162 [==============================] - 1s 6ms/step - loss: 0.3673\n",
      "Epoch 8/10\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.3652\n",
      "Epoch 9/10\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.3619\n",
      "Epoch 10/10\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.3612\n",
      "81/81 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.4684\n",
      "Epoch 2/10\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.4137\n",
      "Epoch 3/10\n",
      "162/162 [==============================] - 1s 6ms/step - loss: 0.4014\n",
      "Epoch 4/10\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.3929\n",
      "Epoch 5/10\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.3840\n",
      "Epoch 6/10\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.3796\n",
      "Epoch 7/10\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.3769\n",
      "Epoch 8/10\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.3716\n",
      "Epoch 9/10\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.3713\n",
      "Epoch 10/10\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.3684\n",
      "81/81 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.4592\n",
      "Epoch 2/10\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.4048\n",
      "Epoch 3/10\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.3911\n",
      "Epoch 4/10\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.3800\n",
      "Epoch 5/10\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.3776\n",
      "Epoch 6/10\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.3669\n",
      "Epoch 7/10\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.3657\n",
      "Epoch 8/10\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.3636\n",
      "Epoch 9/10\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.3619\n",
      "Epoch 10/10\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.3588\n",
      "81/81 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.6356\n",
      "Epoch 2/10\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.5723\n",
      "Epoch 3/10\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.5355\n",
      "Epoch 4/10\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.5106\n",
      "Epoch 5/10\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.4918\n",
      "Epoch 6/10\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.4783\n",
      "Epoch 7/10\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.4686\n",
      "Epoch 8/10\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.4588\n",
      "Epoch 9/10\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.4526\n",
      "Epoch 10/10\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.4446\n",
      "81/81 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.6554\n",
      "Epoch 2/10\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.5882\n",
      "Epoch 3/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 0.5463\n",
      "Epoch 4/10\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.5167\n",
      "Epoch 5/10\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.4969\n",
      "Epoch 6/10\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.4823\n",
      "Epoch 7/10\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.4720\n",
      "Epoch 8/10\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.4618\n",
      "Epoch 9/10\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.4566\n",
      "Epoch 10/10\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.4516\n",
      "81/81 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.6607\n",
      "Epoch 2/10\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.5875\n",
      "Epoch 3/10\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.5434\n",
      "Epoch 4/10\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.5153\n",
      "Epoch 5/10\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.4948\n",
      "Epoch 6/10\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.4788\n",
      "Epoch 7/10\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.4687\n",
      "Epoch 8/10\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.4587\n",
      "Epoch 9/10\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.4527\n",
      "Epoch 10/10\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.4481\n",
      "81/81 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.6670\n",
      "Epoch 2/10\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.5835\n",
      "Epoch 3/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 0.5396\n",
      "Epoch 4/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 0.5133\n",
      "Epoch 5/10\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.4950\n",
      "Epoch 6/10\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.4814\n",
      "Epoch 7/10\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.4706\n",
      "Epoch 8/10\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.4620\n",
      "Epoch 9/10\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.4550\n",
      "Epoch 10/10\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.4491\n",
      "81/81 [==============================] - 0s 3ms/step\n",
      "Epoch 1/10\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.6533\n",
      "Epoch 2/10\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.5923\n",
      "Epoch 3/10\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.5527\n",
      "Epoch 4/10\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.5256\n",
      "Epoch 5/10\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.5059\n",
      "Epoch 6/10\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.4912\n",
      "Epoch 7/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 0.4798\n",
      "Epoch 8/10\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.4709\n",
      "Epoch 9/10\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.4638\n",
      "Epoch 10/10\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.4580\n",
      "81/81 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.7140\n",
      "Epoch 2/10\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.6288\n",
      "Epoch 3/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 0.5781\n",
      "Epoch 4/10\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.5439\n",
      "Epoch 5/10\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.5185\n",
      "Epoch 6/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 0.4985\n",
      "Epoch 7/10\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.4828\n",
      "Epoch 8/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 0.4701\n",
      "Epoch 9/10\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.4600\n",
      "Epoch 10/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 0.4519\n",
      "81/81 [==============================] - 0s 3ms/step\n",
      "Epoch 1/10\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.6071\n",
      "Epoch 2/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 0.5292\n",
      "Epoch 3/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 0.4949\n",
      "Epoch 4/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 0.4749\n",
      "Epoch 5/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 0.4621\n",
      "Epoch 6/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 0.4534\n",
      "Epoch 7/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 0.4468\n",
      "Epoch 8/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 0.4424\n",
      "Epoch 9/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 0.4387\n",
      "Epoch 10/10\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.4357\n",
      "81/81 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.6114\n",
      "Epoch 2/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 0.5331\n",
      "Epoch 3/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 0.4992\n",
      "Epoch 4/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 0.4798\n",
      "Epoch 5/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 0.4674\n",
      "Epoch 6/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 0.4590\n",
      "Epoch 7/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 0.4529\n",
      "Epoch 8/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 0.4483\n",
      "Epoch 9/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 0.4446\n",
      "Epoch 10/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 0.4417\n",
      "81/81 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.6235\n",
      "Epoch 2/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 0.5304\n",
      "Epoch 3/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 0.4969\n",
      "Epoch 4/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 0.4769\n",
      "Epoch 5/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 0.4640\n",
      "Epoch 6/10\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.4549\n",
      "Epoch 7/10\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.4487\n",
      "Epoch 8/10\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.4439\n",
      "Epoch 9/10\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.4401\n",
      "Epoch 10/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 0.4371\n",
      "81/81 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "243/243 [==============================] - 2s 5ms/step - loss: 0.4506\n",
      "Epoch 2/10\n",
      "243/243 [==============================] - 1s 5ms/step - loss: 0.4004\n",
      "Epoch 3/10\n",
      "243/243 [==============================] - 1s 5ms/step - loss: 0.3856\n",
      "Epoch 4/10\n",
      "243/243 [==============================] - 1s 5ms/step - loss: 0.3765\n",
      "Epoch 5/10\n",
      "243/243 [==============================] - 1s 5ms/step - loss: 0.3695\n",
      "Epoch 6/10\n",
      "243/243 [==============================] - 1s 5ms/step - loss: 0.3684\n",
      "Epoch 7/10\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 0.3662\n",
      "Epoch 8/10\n",
      "243/243 [==============================] - 1s 5ms/step - loss: 0.3612\n",
      "Epoch 9/10\n",
      "243/243 [==============================] - 1s 6ms/step - loss: 0.3604\n",
      "Epoch 10/10\n",
      "243/243 [==============================] - 1s 5ms/step - loss: 0.3584\n",
      "CPU times: total: 29.3 s\n",
      "Wall time: 2min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "#from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(\n",
    "    estimator=keras_clf, \n",
    "    param_distributions=params, \n",
    "    scoring='recall',  # we could use any appropriate sklearn metric here (i.e. accuracy, f1_micro, f1_macro)\n",
    "    n_iter=5, \n",
    "    cv=3)\n",
    "\n",
    "# In rare cases, you may find your model training results in exceeding python's default recursion limit.\n",
    "# If needed, you can increase this excersion limit by using the following code.\n",
    "#import sys\n",
    "#sys.setrecursionlimit(10000) # note: the default is 3000 (python 3.9)\n",
    "\n",
    "_ = rnd_search_cv.fit(X_train, y_train,  verbose=1)\n",
    "\n",
    "# You can create 'call back' functions. These are functions that will be called at the \n",
    "# end of each epoch. There are a number of builtin functions created for this purpose, \n",
    "# one of which is EarlyStopping -- that, based on the parameters you give, will stop\n",
    "# the training process. This is useful when the algorithm is not making any significant\n",
    "# gains through further training. \n",
    "#earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')\n",
    "#callback = [earlystop]\n",
    "#_ = rnd_search_cv.fit(X_train, y_train, callbacks=callback, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "65d2dbc0-2f05-4da3-889a-ab17f4a58ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'optimizer__learning_rate': 0.001,\n",
       " 'optimizer': 'adam',\n",
       " 'model__hidden_layer_sizes': (100, 90),\n",
       " 'model__dropout': 0.1,\n",
       " 'loss': 'binary_crossentropy',\n",
       " 'epochs': 10,\n",
       " 'batch_size': 60}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bbc47dd7-fcbe-4093-a49c-539cb8c1aa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = rnd_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d93cee50-50f8-4f5c-a84a-4fb8a41b9a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 3ms/step\n",
      "best score 0.8556366585563666\n",
      "min loss 0.3583610951900482\n",
      "CPU times: total: 141 ms\n",
      "Wall time: 360 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(f\"best score {best_model.score(X_test, y_test)}\")\n",
    "print(f\"min loss {min(best_model.history_['loss'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b2a05bf2-e0d6-4251-9fa0-92ed3d4a8fd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'loss': [0.4506235122680664,\n",
       "              0.4004330635070801,\n",
       "              0.38564833998680115,\n",
       "              0.37650027871131897,\n",
       "              0.369480699300766,\n",
       "              0.3683628439903259,\n",
       "              0.36624133586883545,\n",
       "              0.3611660301685333,\n",
       "              0.3603729009628296,\n",
       "              0.3583610951900482]})"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.history_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d7483d63-28c3-47f3-84f7-113c4f4eef8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 3ms/step\n",
      "************************************\n",
      "Recall Score:     0.8036363636363636\n",
      "************************************\n",
      "Accuracy Score:   0.8556366585563666\n",
      "Precision Score:  0.5092165898617511\n",
      "F1 Score:         0.6234132581100141\n",
      "************************************\n",
      "Confusion Matrix: [[2723  426]\n",
      " [ 108  442]]\n",
      "CPU times: total: 78.1 ms\n",
      "Wall time: 346 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# evaluate the model\n",
    "# predict on test data with default threshold\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# adjust the threshold and predict again\n",
    "new_threshold = 0.3\n",
    "y_pred_thresh = (y_pred >= new_threshold).astype(int)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "# calculate evaluation metrics with adjusted threshold\n",
    "print(\"************************************\")\n",
    "print(f\"{'Recall Score:':18}{recall_score(y_test, y_pred_thresh)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Accuracy Score: ':18}{accuracy_score(y_test, y_pred_thresh)}\")\n",
    "print(f\"{'Precision Score: ':18}{precision_score(y_test, y_pred_thresh)}\")\n",
    "print(f\"{'F1 Score: ':18}{f1_score(y_test, y_pred_thresh)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Confusion Matrix: ':18}{confusion_matrix(y_test, y_pred_thresh)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "18cf9fc9-e44c-44c8-bd4e-9bf9f6877468",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dnn_random_recall = recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef051dde-c778-4294-b1ea-97d72dd5e921",
   "metadata": {},
   "source": [
    "# 3.20 Deep Network deafult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "279dfa13-3a32-4fbe-b0f1-08f918100b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the model\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Input(shape=13))\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "model.add(keras.layers.Dense(90, activation='relu'))\n",
    "model.add(keras.layers.Dense(30, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bf9e03da-274b-4fa1-8be1-1b2a9268767c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "def recall(y_test, y_pred):\n",
    "    y_test = K.ones_like(y_test)\n",
    "    true_positives = K.sum(K.round(K.clip(y_test * y_pred, 0, 1)))\n",
    "    all_positives = K.sum(K.round(K.clip(y_test, 0, 1)))\n",
    "\n",
    "    recall = true_positives / (all_positives + K.epsilon())\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "26ee5df5-7dd2-4554-8da9-84743312e62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "\n",
    "#Optimizer:\n",
    "adam = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=[recall])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cceebe3a-528e-4754-9428-a1040bb0cb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "146/146 [==============================] - 2s 7ms/step - loss: 0.4133 - recall: 0.4795 - val_loss: 0.4140 - val_recall: 0.2287\n",
      "Epoch 2/20\n",
      "146/146 [==============================] - 1s 8ms/step - loss: 0.3866 - recall: 0.4796 - val_loss: 0.3252 - val_recall: 0.2084\n",
      "Epoch 3/20\n",
      "146/146 [==============================] - 1s 9ms/step - loss: 0.3759 - recall: 0.4740 - val_loss: 0.3951 - val_recall: 0.2830\n",
      "Epoch 4/20\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 0.3674 - recall: 0.4768 - val_loss: 0.3749 - val_recall: 0.2414\n",
      "Epoch 5/20\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 0.3586 - recall: 0.4804 - val_loss: 0.3611 - val_recall: 0.2255\n",
      "Epoch 6/20\n",
      "146/146 [==============================] - 1s 6ms/step - loss: 0.3577 - recall: 0.4884 - val_loss: 0.3590 - val_recall: 0.2482\n",
      "Epoch 7/20\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 0.3529 - recall: 0.4859 - val_loss: 0.4162 - val_recall: 0.2552\n",
      "Epoch 8/20\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 0.3489 - recall: 0.4918 - val_loss: 0.4260 - val_recall: 0.2465\n",
      "Epoch 9/20\n",
      "146/146 [==============================] - 1s 6ms/step - loss: 0.3460 - recall: 0.4977 - val_loss: 0.3718 - val_recall: 0.2457\n",
      "Epoch 10/20\n",
      "146/146 [==============================] - 1s 6ms/step - loss: 0.3423 - recall: 0.5003 - val_loss: 0.3829 - val_recall: 0.2573\n",
      "Epoch 11/20\n",
      "146/146 [==============================] - 1s 6ms/step - loss: 0.3344 - recall: 0.5011 - val_loss: 0.3595 - val_recall: 0.2519\n",
      "Epoch 12/20\n",
      "146/146 [==============================] - 1s 6ms/step - loss: 0.3272 - recall: 0.5043 - val_loss: 0.4005 - val_recall: 0.2573\n",
      "Epoch 13/20\n",
      "146/146 [==============================] - 1s 6ms/step - loss: 0.3281 - recall: 0.5055 - val_loss: 0.4001 - val_recall: 0.2603\n",
      "Epoch 14/20\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 0.3215 - recall: 0.5068 - val_loss: 0.3919 - val_recall: 0.2336\n",
      "Epoch 15/20\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 0.3153 - recall: 0.5058 - val_loss: 0.4175 - val_recall: 0.2292\n",
      "Epoch 16/20\n",
      "146/146 [==============================] - 1s 6ms/step - loss: 0.3136 - recall: 0.5073 - val_loss: 0.3985 - val_recall: 0.2400\n",
      "Epoch 17/20\n",
      "146/146 [==============================] - 1s 6ms/step - loss: 0.3117 - recall: 0.5062 - val_loss: 0.4304 - val_recall: 0.2449\n",
      "Epoch 18/20\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 0.3044 - recall: 0.5090 - val_loss: 0.3902 - val_recall: 0.2430\n",
      "Epoch 19/20\n",
      "146/146 [==============================] - 1s 6ms/step - loss: 0.2982 - recall: 0.5074 - val_loss: 0.3903 - val_recall: 0.2433\n",
      "Epoch 20/20\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 0.2902 - recall: 0.5115 - val_loss: 0.3991 - val_recall: 0.2217\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    epochs=20, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "629eb0a4-9617-451e-a4a5-dfee7544c544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 1s 4ms/step\n",
      "************************************\n",
      "Recall Score:     0.7981818181818182\n",
      "************************************\n",
      "Accuracy Score:   0.8386050283860503\n",
      "Precision Score:  0.4745945945945946\n",
      "F1 Score:         0.5952542372881355\n",
      "************************************\n",
      "Confusion Matrix: [[2663  486]\n",
      " [ 111  439]]\n",
      "CPU times: total: 234 ms\n",
      "Wall time: 795 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# evaluate the model\n",
    "# predict on test data with default threshold\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# adjust the threshold and predict again\n",
    "new_threshold = 0.3\n",
    "y_pred_thresh = (y_pred >= new_threshold).astype(int)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "# calculate evaluation metrics with adjusted threshold\n",
    "print(\"************************************\")\n",
    "print(f\"{'Recall Score:':18}{recall_score(y_test, y_pred_thresh)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Accuracy Score: ':18}{accuracy_score(y_test, y_pred_thresh)}\")\n",
    "print(f\"{'Precision Score: ':18}{precision_score(y_test, y_pred_thresh)}\")\n",
    "print(f\"{'F1 Score: ':18}{f1_score(y_test, y_pred_thresh)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Confusion Matrix: ':18}{confusion_matrix(y_test, y_pred_thresh)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cd37376a-6895-434c-ad39-470d33a40e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dnn_default_recall = recall_score(y_test, y_pred_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d9b860-76d8-4b76-a272-6ba8e17755d3",
   "metadata": {},
   "source": [
    "# 3.21 DNN Random Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "403db373-1cc1-402d-88e6-e12f3278feac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# If you don't have the following installed, from command line '!pip install scikeras'\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from keras.initializers import GlorotNormal\n",
    "from keras.initializers import lecun_normal\n",
    "\n",
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "def build_clf(hidden_layer_sizes, dropout):\n",
    "    ann = tf.keras.models.Sequential()\n",
    "    ann.add(keras.layers.Input(shape=13)),\n",
    "    for hidden_layer_size in hidden_layer_sizes:\n",
    "        model.add(keras.layers.Dense(hidden_layer_size, kernel_initializer= tf.keras.initializers.lecun_normal(), \n",
    "                                     bias_initializer=keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None), activation=\"selu\"))\n",
    "        model.add(keras.layers.Dropout(dropout))\n",
    "    ann.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    ann.compile(loss = 'binary_crossentropy', metrics = [recall])\n",
    "    return ann\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "821f62ec-1ace-41a9-a811-7a4a22d131fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "keras_clf = KerasClassifier(\n",
    "    model=build_clf,\n",
    "    hidden_layer_sizes=13,\n",
    "    dropout = 0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "755f58a9-ecb3-4f3a-9473-32381882fba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['model', 'build_fn', 'warm_start', 'random_state', 'optimizer', 'loss', 'metrics', 'batch_size', 'validation_batch_size', 'verbose', 'callbacks', 'validation_split', 'shuffle', 'run_eagerly', 'epochs', 'hidden_layer_sizes', 'dropout', 'class_weight'])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "params = {\n",
    "    'optimizer__learning_rate': [0.0005, 0.001, 0.005],\n",
    "    'model__hidden_layer_sizes': [(70,),(90, ), (100,), (100, 90)],\n",
    "    'model__dropout': [0, 0.1],\n",
    "    'batch_size':[50, 100],\n",
    "    'epochs':[10, 20],\n",
    "    'optimizer':[\"adam\"]\n",
    "}\n",
    "keras_clf.get_params().keys()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2c6075fd-186a-42fc-9bae-fb998b2e000a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 0s 2ms/step\n",
      "59/59 [==============================] - 0s 2ms/step\n",
      "59/59 [==============================] - 0s 2ms/step\n",
      "59/59 [==============================] - 0s 2ms/step\n",
      "59/59 [==============================] - 0s 2ms/step\n",
      "59/59 [==============================] - 0s 2ms/step\n",
      "59/59 [==============================] - 0s 2ms/step\n",
      "59/59 [==============================] - 0s 2ms/step\n",
      "59/59 [==============================] - 0s 2ms/step\n",
      "59/59 [==============================] - 0s 1ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "59/59 [==============================] - 0s 2ms/step\n",
      "59/59 [==============================] - 0s 2ms/step\n",
      "59/59 [==============================] - 0s 2ms/step\n",
      "59/59 [==============================] - 0s 2ms/step\n",
      "59/59 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "59/59 [==============================] - 0s 2ms/step\n",
      "59/59 [==============================] - 0s 1ms/step\n",
      "59/59 [==============================] - 0s 2ms/step\n",
      "59/59 [==============================] - 0s 1ms/step\n",
      "59/59 [==============================] - 0s 2ms/step\n",
      "59/59 [==============================] - 0s 2ms/step\n",
      "59/59 [==============================] - 0s 2ms/step\n",
      "59/59 [==============================] - 0s 2ms/step\n",
      "59/59 [==============================] - 0s 2ms/step\n",
      "59/59 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "CPU times: total: 1min 35s\n",
      "Wall time: 5min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rnd_search_cv = RandomizedSearchCV(estimator=keras_clf, param_distributions=params, scoring=score_measure, n_iter=10, cv=5)\n",
    "\n",
    "import sys\n",
    "sys.setrecursionlimit(3000) # note: the default is 3000 (python 3.9)\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')\n",
    "callback = [earlystop]\n",
    "\n",
    "_ = rnd_search_cv.fit(X_train, y_train, callbacks=callback, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "086d2d3b-5a26-4da6-836b-e53253b5dbaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'optimizer__learning_rate': 0.0005,\n",
       " 'optimizer': 'adam',\n",
       " 'model__hidden_layer_sizes': (70,),\n",
       " 'model__dropout': 0.1,\n",
       " 'epochs': 10,\n",
       " 'batch_size': 100}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6df6258e-a29a-4703-ac32-1e2e68a087b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'optimizer__learning_rate': 0.0005, 'optimizer': 'adam', 'model__hidden_layer_sizes': (70,), 'model__dropout': 0.1, 'epochs': 10, 'batch_size': 100}\n"
     ]
    }
   ],
   "source": [
    "best_net = rnd_search_cv.best_estimator_\n",
    "print(rnd_search_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6a5ad69e-89cf-472d-bed2-25d2288ba9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 1s 4ms/step\n",
      "************************************\n",
      "Recall Score:     0.7981818181818182\n",
      "************************************\n",
      "Accuracy Score:   0.8386050283860503\n",
      "Precision Score:  0.4745945945945946\n",
      "F1 Score:         0.5952542372881355\n",
      "************************************\n",
      "Confusion Matrix: [[2663  486]\n",
      " [ 111  439]]\n",
      "CPU times: total: 172 ms\n",
      "Wall time: 680 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# evaluate the model\n",
    "# predict on test data with default threshold\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# adjust the threshold and predict again\n",
    "new_threshold = 0.3\n",
    "y_pred_thresh = (y_pred >= new_threshold).astype(int)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "# calculate evaluation metrics with adjusted threshold\n",
    "print(\"************************************\")\n",
    "print(f\"{'Recall Score:':18}{recall_score(y_test, y_pred_thresh)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Accuracy Score: ':18}{accuracy_score(y_test, y_pred_thresh)}\")\n",
    "print(f\"{'Precision Score: ':18}{precision_score(y_test, y_pred_thresh)}\")\n",
    "print(f\"{'F1 Score: ':18}{f1_score(y_test, y_pred_thresh)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Confusion Matrix: ':18}{confusion_matrix(y_test, y_pred_thresh)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "66a555fd-b06d-41ac-bb5b-4abf29d69388",
   "metadata": {},
   "outputs": [],
   "source": [
    "DNN_randgrid_recall = recall_score(y_test, y_pred_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6620fb66-dd98-4622-8a01-4719857b3cae",
   "metadata": {},
   "source": [
    "# 3.22 Wide and Deep Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "16bb2668-02d3-4847-b50e-51fb049e03ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the model: for multi-class\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Input(shape=13))\n",
    "model.add(keras.layers.Dense(200, activation='relu'))\n",
    "model.add(keras.layers.Dense(200, activation='relu'))\n",
    "model.add(keras.layers.Dense(200, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d83af35e-796b-4cb3-950d-37eb5197bf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "\n",
    "#Optimizer:\n",
    "adam = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=[recall])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c1289fb5-3616-4dd9-b78a-310a6db30568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "146/146 [==============================] - 2s 8ms/step - loss: 0.4200 - recall: 0.4778 - val_loss: 0.4026 - val_recall: 0.2306\n",
      "Epoch 2/20\n",
      "146/146 [==============================] - 1s 8ms/step - loss: 0.3856 - recall: 0.4777 - val_loss: 0.3398 - val_recall: 0.2122\n",
      "Epoch 3/20\n",
      "146/146 [==============================] - 1s 8ms/step - loss: 0.3819 - recall: 0.4744 - val_loss: 0.3579 - val_recall: 0.2665\n",
      "Epoch 4/20\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 0.3700 - recall: 0.4886 - val_loss: 0.3755 - val_recall: 0.2565\n",
      "Epoch 5/20\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 0.3610 - recall: 0.4841 - val_loss: 0.3925 - val_recall: 0.2390\n",
      "Epoch 6/20\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 0.3582 - recall: 0.4896 - val_loss: 0.3894 - val_recall: 0.2649\n",
      "Epoch 7/20\n",
      "146/146 [==============================] - 1s 6ms/step - loss: 0.3562 - recall: 0.4923 - val_loss: 0.3951 - val_recall: 0.2355\n",
      "Epoch 8/20\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 0.3479 - recall: 0.4935 - val_loss: 0.4315 - val_recall: 0.2603\n",
      "Epoch 9/20\n",
      "146/146 [==============================] - 1s 8ms/step - loss: 0.3426 - recall: 0.4929 - val_loss: 0.3433 - val_recall: 0.2268\n",
      "Epoch 10/20\n",
      "146/146 [==============================] - 1s 9ms/step - loss: 0.3391 - recall: 0.4984 - val_loss: 0.3862 - val_recall: 0.2603\n",
      "Epoch 11/20\n",
      "146/146 [==============================] - 1s 8ms/step - loss: 0.3338 - recall: 0.4975 - val_loss: 0.3552 - val_recall: 0.2290\n",
      "Epoch 12/20\n",
      "146/146 [==============================] - 1s 6ms/step - loss: 0.3268 - recall: 0.5018 - val_loss: 0.4153 - val_recall: 0.2436\n",
      "Epoch 13/20\n",
      "146/146 [==============================] - 1s 6ms/step - loss: 0.3338 - recall: 0.5012 - val_loss: 0.3875 - val_recall: 0.2541\n",
      "Epoch 14/20\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 0.3231 - recall: 0.5041 - val_loss: 0.3840 - val_recall: 0.2455\n",
      "Epoch 15/20\n",
      "146/146 [==============================] - 1s 6ms/step - loss: 0.3149 - recall: 0.5018 - val_loss: 0.4317 - val_recall: 0.2636\n",
      "Epoch 16/20\n",
      "146/146 [==============================] - 1s 6ms/step - loss: 0.3107 - recall: 0.5075 - val_loss: 0.3699 - val_recall: 0.2282\n",
      "Epoch 17/20\n",
      "146/146 [==============================] - 1s 6ms/step - loss: 0.3042 - recall: 0.5103 - val_loss: 0.4311 - val_recall: 0.2330\n",
      "Epoch 18/20\n",
      "146/146 [==============================] - 1s 6ms/step - loss: 0.3003 - recall: 0.5100 - val_loss: 0.3944 - val_recall: 0.2311\n",
      "Epoch 19/20\n",
      "146/146 [==============================] - 1s 6ms/step - loss: 0.2927 - recall: 0.5109 - val_loss: 0.3908 - val_recall: 0.2271\n",
      "Epoch 20/20\n",
      "146/146 [==============================] - 1s 6ms/step - loss: 0.2889 - recall: 0.5108 - val_loss: 0.3797 - val_recall: 0.2282\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    epochs=20, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "92d04e51-c0d4-4331-ab55-2f11e4299050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 0s 3ms/step\n",
      "************************************\n",
      "Recall Score:     0.82\n",
      "************************************\n",
      "Accuracy Score:   0.8188699648553663\n",
      "Precision Score:  0.44129158512720157\n",
      "F1 Score:         0.5737913486005088\n",
      "************************************\n",
      "Confusion Matrix: [[2578  571]\n",
      " [  99  451]]\n",
      "CPU times: total: 188 ms\n",
      "Wall time: 540 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# evaluate the model\n",
    "# predict on test data with default threshold\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# adjust the threshold and predict again\n",
    "new_threshold = 0.3\n",
    "y_pred_thresh = (y_pred >= new_threshold).astype(int)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "# calculate evaluation metrics with adjusted threshold\n",
    "print(\"************************************\")\n",
    "print(f\"{'Recall Score:':18}{recall_score(y_test, y_pred_thresh)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Accuracy Score: ':18}{accuracy_score(y_test, y_pred_thresh)}\")\n",
    "print(f\"{'Precision Score: ':18}{precision_score(y_test, y_pred_thresh)}\")\n",
    "print(f\"{'F1 Score: ':18}{f1_score(y_test, y_pred_thresh)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Confusion Matrix: ':18}{confusion_matrix(y_test, y_pred_thresh)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5c2e472c-c64d-415a-8a69-e4cfdbeb8866",
   "metadata": {},
   "outputs": [],
   "source": [
    "WDNN_recall = recall_score(y_test, y_pred_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bd0744",
   "metadata": {
    "id": "69bd0744"
   },
   "source": [
    "# 4.0 Summarize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "16efe952",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "16efe952",
    "outputId": "11915186-c930-4b08-a307-059e399d810a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall scores...\n",
      "**************************************\n",
      "Logistic Regression deafult:0.7454545454545455\n",
      "Logistic Regression Random Search:0.7454545454545455\n",
      "Logistic Regression Grid Search:0.7454545454545455\n",
      "**************************************\n",
      "SVM Linear deafult:0.730909090909091\n",
      "SVM Linear Random Search:0.730909090909091\n",
      "SVM Linear Grid Search:0.730909090909091\n",
      "**************************************\n",
      "SVM rbf deafult:  0.7490909090909091\n",
      "SVM rbf Random Search:0.7345454545454545\n",
      "SVM rbf Grid Search:0.7327272727272728\n",
      "**************************************\n",
      "SVM Poly deafult: 0.7345454545454545\n",
      "SVM Poly Random Search:0.7163636363636363\n",
      "SVM Poly Grid Search:0.7163636363636363\n",
      "**************************************\n",
      "Decision Tree deafult:0.5636363636363636\n",
      "Decision Tree Random Search:0.8490909090909091\n",
      "Decision Tree Grid Search:0.8345454545454546\n",
      "**************************************\n",
      "ANN deafult:      0.6290909090909091\n",
      "ANN Random Search:0.649090909090909\n",
      "ANN Grid Search:  0.8545454545454545\n",
      "**************************************\n",
      "**************************************\n",
      "DNN with Random Search:0.8036363636363636\n",
      "DNN deafult :     0.7981818181818182\n",
      "DNN with Random Grid Search:0.7981818181818182\n",
      "WDNN:             0.82\n",
      "**************************************\n",
      "**************************************\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall scores...\")\n",
    "print(\"**************************************\")\n",
    "print(f\"{'Logistic Regression deafult:':18}{lr_default_recall}\")\n",
    "print(f\"{'Logistic Regression Random Search:':18}{lr_rand_recall}\")\n",
    "print(f\"{'Logistic Regression Grid Search:':18}{lr_grid_recall}\")\n",
    "print(\"**************************************\")\n",
    "print(f\"{'SVM Linear deafult:':18}{svm_linear_default_recall}\")\n",
    "print(f\"{'SVM Linear Random Search:':18}{svm_linear_rand_recall}\")\n",
    "print(f\"{'SVM Linear Grid Search:':18}{svm_linear_grid_recall}\")\n",
    "print(\"**************************************\")\n",
    "print(f\"{'SVM rbf deafult:':18}{svm_rbf_default_recall}\")\n",
    "print(f\"{'SVM rbf Random Search:':18}{svm_rbf_rand_recall}\")\n",
    "print(f\"{'SVM rbf Grid Search:':18}{svm_rbf_grid_recall}\")\n",
    "print(\"**************************************\")\n",
    "print(f\"{'SVM Poly deafult:':18}{svm_poly_default_recall}\")\n",
    "print(f\"{'SVM Poly Random Search:':18}{svm_poly_rand_recall}\")\n",
    "print(f\"{'SVM Poly Grid Search:':18}{svm_poly_grid_recall}\")\n",
    "print(\"**************************************\")\n",
    "print(f\"{'Decision Tree deafult:':18}{dtree_default_recall}\")\n",
    "print(f\"{'Decision Tree Random Search:':18}{dtree_rand_recall}\")\n",
    "print(f\"{'Decision Tree Grid Search:':18}{dtree_grid_recall}\")\n",
    "print(\"**************************************\")\n",
    "print(f\"{'ANN deafult:':18}{ann_default_recall}\")\n",
    "print(f\"{'ANN Random Search:':18}{ann_random_recall}\")\n",
    "print(f\"{'ANN Grid Search:':18}{ann_grid_recall}\")\n",
    "print(\"**************************************\")\n",
    "print(\"**************************************\")\n",
    "print(f\"{'DNN with Random Search:':18}{Dnn_random_recall}\")\n",
    "print(f\"{'DNN deafult :':18}{Dnn_default_recall}\")\n",
    "print(f\"{'DNN with Random Grid Search:':18}{DNN_randgrid_recall}\")\n",
    "print(f\"{'WDNN:':18}{WDNN_recall}\")\n",
    "print(\"**************************************\")\n",
    "print(\"**************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baae92bf-0e05-417b-87aa-48bde1711070",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76182e1",
   "metadata": {
    "id": "BaI5RSJPbrzi"
   },
   "source": [
    "##### As the company is new to market and they want to improve potential customer in coming three year regardless of their marketing budget spending  so we used recall score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d21dce7-3fcf-432a-9e99-97afe566ca8f",
   "metadata": {},
   "source": [
    "# MLP and Keras models perform versus other predictive models.\n",
    "\n",
    "Based on the recall scores, the MLP-ANN (Multi-layer Perceptron Artificial Neural Network) models perform worse than some of the other models, such as the decision tree models, SVM models (with radial basis function kernel), and the DNN (Deep Neural Network) models. However, the MLP-ANN model with Grid Search hyperparameter tuning achieved a recall score of 0.8545, which is higher than any other model except the decision tree with Random Search tuning. This indicates that the MLP-ANN model has the potential to perform well, but it may require more extensive hyperparameter tuning to achieve optimal performance.\n",
    "\n",
    "On the other hand, the DNN models with Random Search, default settings, Random Grid Search, and Wide DNN perform relatively well, achieving recall scores ranging from 0.7982 to 0.82. These scores are competitive with the best-performing models, such as the decision tree with Random Search and the MLP-ANN with Grid Search. This suggests that the DNN models have potential for good performance and may be worth further investigation and optimization for better results."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
